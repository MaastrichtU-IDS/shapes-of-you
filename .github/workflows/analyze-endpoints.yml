name: Analyze SPARQL endpoints
on:
  schedule:
    # Every Sunday at 01:00 
    - cron:  '0 1 * * 0'
  workflow_dispatch:

jobs:

  get-endpoints-matrix:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ toJson(fromJson(steps.generate-matrix.outputs.matrix).results.bindings) }}

    steps:
      - uses: actions/checkout@v2

      - name: Get list of endpoints
        id: generate-matrix
        run: |
          curl -X GET -H "accept: application/json" -o endpoints.json "https://data.index.semanticscience.org/sparql?query=$(cat api/get-active-endpoints.rq | python3 -c 'import urllib.parse, sys; print(urllib.parse.quote(sys.stdin.read()))')"
          # curl -X GET -H "accept: application/json" -o endpoints.json "https://graphdb.dumontierlab.com/repositories/shapes-registry?query=$(cat api/get-active-endpoints.rq | python3 -c 'import urllib.parse, sys; print(urllib.parse.quote(sys.stdin.read()))')"
          endpoints_json=$( cat endpoints.json )
          echo $endpoints_json
          echo ::set-output name=matrix::$endpoints_json
      
        # Construct SPARQL query:
        # curl -X GET -H "accept: text/turtle" -o neurodkg.ttl "https://graphdb.dumontierlab.com/repositories/NeuroDKG?query=$(cat convert2biolink.rq | python3 -c 'import urllib.parse, sys; print(urllib.parse.quote(sys.stdin.read()))')"


  analyze-endpoints:
    runs-on: ubuntu-latest
    needs: get-endpoints-matrix
    strategy:
      fail-fast: false
      matrix:
        endpoint-url: ${{ fromJson(needs.get-endpoints-matrix.outputs.matrix) }}

    steps:
    # - name: Check matrix
    #   env:
    #     # MATRIX: ${{ needs.get-endpoints-matrix.outputs.matrix }}
    #     MATRIX: "${{ matrix.endpoint-url.sparql_endpoint.value }}"
    #   run: |
    #     echo $MATRIX
    #     # endpoint=$( echo $MATRIX | jq -r '.sparql_endpoint.value' )
    #     # echo $endpoint
    #     # echo "ENDPOINT_URL=${endpoint}" >> $GITHUB_ENV

    - uses: actions/checkout@v2
      with:
        ref: 'metadata'

    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: 3.8
    - uses: actions/cache@v2
      name: Configure pip caching
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    - name: Install Python requirements
      env:
        SPARQL_ENDPOINT_URL: ${{ matrix.endpoint-url.sparql_endpoint.value }}
      run: |
        pip install git+https://github.com/MaastrichtU-IDS/d2s-cli.git@master
        export ENDPOINT_LABEL=${SPARQL_ENDPOINT_URL//https:/}
        export ENDPOINT_LABEL=${ENDPOINT_LABEL//http:/}
        echo "ENDPOINT_LABEL=${ENDPOINT_LABEL//\//}" >> $GITHUB_ENV
      # pip install d2s

    - name: Run Python script to compute HCLS metadata for each graph in ${{ matrix.endpoint-url.sparql_endpoint.value }}
      env:
        SPARQL_ENDPOINT_URL: ${{ matrix.endpoint-url.sparql_endpoint.value }}
      run: |
        mkdir -p output
        d2s metadata analyze $SPARQL_ENDPOINT_URL -o output/metadata.ttl
        mv REPORT_FAIL.md output/ || exit 0
        mv REPORT_SUCCESS.md output/ || exit 0

    - name: Upload RDF metadata and md reports to GitHub
      uses: actions/upload-artifact@v1
      with:
        name: report-${{ env.ENDPOINT_LABEL }}
        path: output

    - name: Commit and push metadata-${{ env.ENDPOINT_LABEL }}.ttl file in metadata branch
      env:
        ENDPOINT_URL: ${{ matrix.endpoint-url.sparql_endpoint.value }}
        ENDPOINT_PASSWORD: ${{ secrets.GRAPHDB_PASSWORD }}
      run: |
        if [ $(wc -l  metadata.ttl | cut -d' ' -f1) -gt $(echo 1) ]
        then
          export ENDPOINT_LABEL=${ENDPOINT_URL//http:/}
          export ENDPOINT_LABEL=${ENDPOINT_LABEL//https:/}
          export ENDPOINT_LABEL=${ENDPOINT_LABEL//\//}
          curl -H "Accept: text/turtle" -H "Content-type: text/turtle" -u ldp:$ENDPOINT_PASSWORD --data-binary @output/metadata.ttl -H "Slug: $ENDPOINT_LABEL" https://data.index.semanticscience.org/DAV/home/ldp/endpoints'
          # git stash
          # git fetch
          # git checkout metadata
          # mv output/metadata.ttl metadata-$ENDPOINT_LABEL.ttl
          # git diff
          # git config --global user.email "vincent.emonet@gmail.com"
          # git config --global user.name "Vincent Emonet"
          # git add metadata-$ENDPOINT_LABEL.ttl
          # git commit -m "metadata-$ENDPOINT_LABEL.ttl" || exit 0
          # git push || exit 0
        fi

    # - name: Upload RDF file to the triplestore
    #   uses: MaastrichtU-IDS/RdfUpload@master
    #   with:
    #     file: output/metadata.ttl
    #     endpoint: https://graphdb.dumontierlab.com/repositories/shapes-registry/statements
    #     # endpoint: https://data.index.semanticscience.org/sparql
    #     user: ${{ secrets.GRAPHDB_USER }}
    #     password: ${{ secrets.GRAPHDB_PASSWORD }}
    #     graph: ${{ matrix.endpoint-url.sparql_endpoint.value }}        

    # - name: Clear older graph in the triplestore
    #   if: github.event.inputs.clear == 'true'
    #   uses: vemonet/sparql-operations-action@v1
    #   with:
    #     query: "CLEAR GRAPH <https://w3id.org/um/ids/shapes>"
    #     endpoint: https://graphdb.dumontierlab.com/repositories/shapes-registry/statements
    #     user: ${{ secrets.GRAPHDB_USER }}
    #     password: ${{ secrets.GRAPHDB_PASSWORD }}

